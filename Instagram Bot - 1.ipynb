{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraris\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import bs4\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Username & Password\n",
    "username = \"SAMPLE USERNAME\"        ## fill it eg: SAMPLE USERNAME\n",
    "password = \"SAMPLE PASSWORD\"                  ## fill it eg: SAMPLE PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up driver\n",
    "path = \"/Users/bhard/Downloads/chromedriver_win32/chromedriver\"   ## depends on sytem\n",
    "driver = webdriver.Chrome(executable_path = path)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## opening site\n",
    "site = \"https://www.instagram.com/\"\n",
    "driver.get(site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log in to Instagram Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for log in\n",
    "\n",
    "def log_in_to_account(driver, username, password):\n",
    "    \n",
    "    login = True\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)  ## explicit wait\n",
    "    \n",
    "    try:\n",
    "        ## move to login page\n",
    "        log_in_path = '//p[@class = \"izU2O\"]//a'\n",
    "        log_in = wait.until(EC.element_to_be_clickable((By.XPATH,log_in_path)))\n",
    "        log_in.click()\n",
    "\n",
    "        time.sleep(3)   ## waiting for website to switch\n",
    "\n",
    "        ## enter username\n",
    "        username_ = wait.until(EC.presence_of_element_located((By.NAME,\"username\")))\n",
    "        username_.send_keys(username)\n",
    "\n",
    "        ## enter password\n",
    "        password_ = wait.until(EC.presence_of_element_located((By.NAME,\"password\")))\n",
    "        password_.send_keys(password)\n",
    "\n",
    "        ## click login\n",
    "        log_in_path = '//button[contains(@class, \"sqdOP\")]'\n",
    "        log_in = wait.until(EC.presence_of_element_located((By.XPATH,log_in_path)))\n",
    "        log_in.submit()\n",
    "\n",
    "        time.sleep(3)  ## waiting for website to switch\n",
    "        \n",
    "    except Exception:\n",
    "        login = False\n",
    "        \n",
    "    if login:\n",
    "        remove_notification(driver, wait)\n",
    "    \n",
    "    return login\n",
    "\n",
    "def remove_notification(driver, wait):\n",
    "    ## Notifination popup setting up not now, if occur\n",
    "    try:\n",
    "        popup_path = '//button[contains(@class, \"HoLwm\")]'\n",
    "        not_now_btn = wait.until(EC.element_to_be_clickable((By.XPATH,popup_path)))\n",
    "        not_now_btn.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"No Notification Pop up occur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log in successfully\n"
     ]
    }
   ],
   "source": [
    "## 1\n",
    "\n",
    "login = log_in_to_account(driver, username, password)\n",
    "if login:\n",
    "    print(\"log in successfully\")\n",
    "else:\n",
    "    print(\"log in unseccussful, give one more try\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Searching Food "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to search something string like 'food' here\n",
    "\n",
    "def Search_Handle(driver, string):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    ## search 'food' \n",
    "    search_path = '//input[contains(@class, \"x3qfX\")]'\n",
    "    search_bar = wait.until(EC.presence_of_element_located((By.XPATH,search_path)))\n",
    "    search_bar.send_keys(string)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    ## Extracting the handles\n",
    "    handles = []\n",
    "    lst = driver.find_elements_by_class_name(\"Ap253\")\n",
    "    for i in lst:\n",
    "        handle = i.get_attribute(\"innerHTML\")\n",
    "        if handle[0] == \"#\":\n",
    "            handle = handle[1:]\n",
    "        handles.append(handle)\n",
    "        \n",
    "    ## Erasing string from search bar\n",
    "    path = '//div[contains(@class, \"coreSpriteSearchClear\")]'\n",
    "    remove_btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "    remove_btn.click()\n",
    "        \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . foodporn\n",
      "2 . food\n",
      "3 . foodphotography\n",
      "4 . foodstagram\n",
      "5 . foodie\n",
      "6 . foodblogger\n",
      "7 . dilsefoodie\n",
      "8 . foodies\n",
      "9 . food.darzee\n",
      "10 . foodrush.recipe\n",
      "11 . foodys\n",
      "12 . foodish_fun\n",
      "13 . foodiesince96\n",
      "14 . food\n",
      "15 . love_food_extra\n",
      "16 . thisisinsiderfood\n",
      "17 . yourfoodlab\n",
      "18 . tabasum_biswas\n",
      "19 . foodopanions\n",
      "20 . foody_bliss\n",
      "21 . food_planet_570\n",
      "22 . foodmapdelhi\n",
      "23 . pinch_of_flavor\n",
      "24 . foodgasms_over_orgasms\n",
      "25 . food_in_city0303\n",
      "26 . foodelhi\n",
      "27 . foodie_incarnate\n",
      "28 . foodshabit\n",
      "29 . foodnetworksofficial\n",
      "30 . sheero_ftd\n",
      "31 . xxfood_chemistryxx\n",
      "32 . foodtalkindia\n",
      "33 . foody_blogs\n",
      "34 . delhifoodwalks\n",
      "35 . delhifoodguide\n",
      "36 . foodie.frens\n",
      "37 . amazing_foody_\n",
      "38 . foodnetwork\n",
      "39 . _.haqsefoodie._\n",
      "40 . buzzfeedfood\n",
      "41 . foodguidelines\n",
      "42 . foodofmumbai\n",
      "43 . mumbaifoodie\n",
      "44 . food.lords\n",
      "45 . foodgully\n",
      "46 . partnersinfood_\n",
      "47 . fbci_official\n",
      "48 . noidafooddiaries\n",
      "49 . foodoholic_bae\n",
      "50 . the_foodie_bae\n",
      "51 . letstalkabout.taste\n",
      "52 . meghnasfoodmagic\n",
      "53 . taken.by.food2\n",
      "54 . mumbaifoodjunkie\n",
      "55 . foodytops\n"
     ]
    }
   ],
   "source": [
    "## 2\n",
    "\n",
    "string = \"food\"     ## can be changed\n",
    "handle_list = Search_Handle(driver, string)\n",
    "cnt = 1\n",
    "for i in handle_list:\n",
    "    print(cnt, \".\", i)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search & Open \"So Delhi\" Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for search_open the profile\n",
    "\n",
    "def search_open(driver, profile):\n",
    "    \n",
    "    open_ = True\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    try:\n",
    "        ## search 'So Delhi' \n",
    "        search_path = '//input[contains(@class, \"x3qfX\")]'\n",
    "        search_bar = wait.until(EC.presence_of_element_located((By.XPATH,search_path)))\n",
    "        search_bar.send_keys(profile)\n",
    "\n",
    "        ## open\n",
    "        path = '//a[contains(@class, \"yCE8d\")]'\n",
    "        btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "        btn.click()\n",
    "    except Exception:\n",
    "        open_ = False\n",
    "        \n",
    "    return open_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for closing profile or returning home page\n",
    "\n",
    "def close_profile(driver):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile is successfully opened\n"
     ]
    }
   ],
   "source": [
    "## 3\n",
    "\n",
    "profile = \"So Delhi\"  ## can be changed\n",
    "\n",
    "## opening profile\n",
    "open_ = search_open(driver, profile)\n",
    "if open_:\n",
    "    print(\"Profile is successfully opened\")\n",
    "else:\n",
    "    print(\"Profile is not opened, try again\")\n",
    "    \n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "## Closing profile\n",
    "close_profile(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Follow / Unfollow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to follow a given handle/profile\n",
    "\n",
    "def follow(driver, profile):\n",
    "    \n",
    "    previously_follow = False\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## following handle\n",
    "    path = '//button[contains(@class, \"_5f5mN\")]'\n",
    "    btn = wait.until(EC.presence_of_element_located((By.XPATH,path)))\n",
    "    \n",
    "    ## Checking if i am following or not\n",
    "    if(btn.get_attribute('innerHTML') == \"Follow\"):\n",
    "        btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "        btn.click()\n",
    "    else:\n",
    "        previously_follow = True\n",
    "        \n",
    "    ## coming back to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return previously_follow    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to unfollow a given profile\n",
    "\n",
    "def unfollow(driver, profile):\n",
    "    \n",
    "    previously_unfollow = False\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## unfollowing handle\n",
    "    path = '//button[contains(@class, \"_5f5mN\")]'\n",
    "    btn = wait.until(EC.presence_of_element_located((By.XPATH,path)))\n",
    "    \n",
    "    ## Checking if i am unfollowing or not\n",
    "    if(btn.get_attribute('innerHTML') != \"Follow\"):\n",
    "        btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "        btn.click()\n",
    "        \n",
    "        ## unfollowing\n",
    "        path = '//button[contains(@class, \"aOOlW \")]'\n",
    "        btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "        btn.click()\n",
    "    else:\n",
    "        previously_unfollow = True\n",
    "        \n",
    "    ## coming back to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return previously_unfollow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Following\n",
      "Start Unfollowing\n"
     ]
    }
   ],
   "source": [
    "## 4\n",
    "\n",
    "profile = \"So Delhi\"        ## can be changed\n",
    "\n",
    "## follow\n",
    "previously_follow = follow(driver, profile)\n",
    "if(previously_follow):\n",
    "    print(\"Already Following\")\n",
    "else:\n",
    "    print(\"Start Following\")\n",
    "    \n",
    "    \n",
    "time.sleep(3)    \n",
    "\n",
    "\n",
    "## unfollow\n",
    "previously_unfollow = unfollow(driver, profile)\n",
    "if(previously_unfollow):\n",
    "    print(\"Already not Following\")\n",
    "else:\n",
    "    print(\"Start Unfollowing\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Like / Unlike "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to liking the first no_of_post of a profile\n",
    "\n",
    "def like(driver, profile, no_of_post):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    previously_like = False\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## Extracting The No_of_posts\n",
    "    btn = driver.find_elements_by_class_name(\"_bz0w\")\n",
    "    path = \"//div[contains(@class,'_bz0w')]/a\"\n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "    while len(btn) < no_of_post:\n",
    "        driver.execute_script('window.scrollBy(0, 1000);')         ## Scrolling\n",
    "        btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "        \n",
    "    print(\"number of posts extracted: \", len(btn))\n",
    "    \n",
    "    cnt = 1\n",
    "    for i in btn:\n",
    "        i.click()\n",
    "        time.sleep(3)\n",
    "        \n",
    "        ## Checking if ith post is liked before or not\n",
    "        cond = driver.find_elements_by_xpath(\"//*[name()='svg']\")[6]\n",
    "        if(cond.get_attribute(\"aria-label\") == \"Like\"):    ## finding the like one\n",
    "            path = '//button[contains(@class, \"wpO6b\")]'\n",
    "            like_unlike = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "            like_unlike.click()\n",
    "        else:\n",
    "            previously_like = True\n",
    "            \n",
    "        ## exiting the post\n",
    "        exit = driver.find_element_by_class_name(\"ckWGn\")\n",
    "        exit.click()\n",
    "        \n",
    "        ## mainatining the number of post\n",
    "        if cnt == no_of_post:\n",
    "            break\n",
    "        cnt += 1\n",
    "        \n",
    "    ## coming back to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return previously_like   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to disliking the first no_of_post of a profile\n",
    "\n",
    "def unlike(driver, profile, no_of_post):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)       ## Explicit Wait\n",
    "    \n",
    "    previously_unlike = False\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## Extracting The No_of_posts\n",
    "    btn = driver.find_elements_by_class_name(\"_bz0w\")\n",
    "    path = \"//div[contains(@class,'_bz0w')]/a\"\n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "    while len(btn) < no_of_post:\n",
    "        driver.execute_script('window.scrollBy(0, 1000);')         ## Scrolling\n",
    "        btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "        \n",
    "    print(\"number of posts extracted: \", len(btn))\n",
    "    \n",
    "    cnt = 1\n",
    "    for i in btn:\n",
    "        i.click()\n",
    "        time.sleep(3)\n",
    "        \n",
    "        ## Checking if ith post is liked before or not\n",
    "        cond = driver.find_elements_by_xpath(\"//*[name()='svg']\")[6]\n",
    "        if(cond.get_attribute(\"aria-label\") == \"Unlike\"):    ## finding the like one\n",
    "            path = '//button[contains(@class, \"wpO6b\")]'\n",
    "            like_unlike = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "            like_unlike.click()\n",
    "        else:\n",
    "            previously_unlike = True\n",
    "            \n",
    "        ## exiting the post\n",
    "        exit = driver.find_element_by_class_name(\"ckWGn\")\n",
    "        exit.click()\n",
    "        \n",
    "        ## mainatining the number of post\n",
    "        if cnt == no_of_post:\n",
    "            break\n",
    "        cnt += 1\n",
    "        \n",
    "    ## coming back to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return previously_unlike   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of posts extracted:  36\n",
      "No Post is liked before\n",
      "number of posts extracted:  30\n",
      "Unliked all now, no post is disliked before\n"
     ]
    }
   ],
   "source": [
    "## 5\n",
    "\n",
    "profile = \"dilsefoodie\"        ## can be changed\n",
    "no_of_post = 30\n",
    "\n",
    "## like\n",
    "previously_like = like(driver, profile, no_of_post)\n",
    "if(previously_like):\n",
    "    print(\"Already one of the post is liked\")\n",
    "else:\n",
    "    print(\"No Post is liked before\")\n",
    "    \n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "    \n",
    "## unlike\n",
    "previously_unlike = unlike(driver, profile, no_of_post)\n",
    "if(previously_unlike):\n",
    "    print(\"Already one of the post is not liked\")\n",
    "else:\n",
    "    print(\"Unliked all now, no post is disliked before\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. list Of Followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to extract the username of no_of_followers folllowers of a profile\n",
    "\n",
    "def extracting_followers(driver, profile, no_of_followers):  \n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)       ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "\n",
    "    ## clicking on followers\n",
    "    path = '//li[contains(@class, \"Y8-fY\")][2]/a'\n",
    "    followers = wait.until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "    followers.click()\n",
    "\n",
    "    ## Extracting The No_of_followers\n",
    "    path = '//div[@class = \"PZuss\"]//li'\n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "\n",
    "    while len(btn) < no_of_followers:\n",
    "        scr1 = driver.find_element_by_xpath('/html/body/div[4]/div/div[2]')                    ## followers window\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scr1)            ## Scrolling\n",
    "        btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "\n",
    "    print(\"number of followers extracted of\", profile ,\":\", len(btn))\n",
    "\n",
    "    ## extracting the content\n",
    "    pg = driver.page_source\n",
    "    data = bs4.BeautifulSoup(pg,\"lxml\")\n",
    "    temp = data.find_all(\"a\",{\"class\":\"FPmhX\"})\n",
    "\n",
    "    ## making the list\n",
    "    followers_ = []\n",
    "    cnt = 1\n",
    "    for k in temp:\n",
    "        followers_.append(k.text)\n",
    "        if cnt == no_of_followers:\n",
    "            break\n",
    "        cnt += 1\n",
    "\n",
    "    ## exiting the followers page\n",
    "    btn = driver.find_element_by_class_name(\"wpO6b \")\n",
    "    btn.click()\n",
    "\n",
    "    ## return to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "        \n",
    "    return followers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract followers of given list of profiles\n",
    "\n",
    "def extract_followers_of_profiles(driver, names, no_of_followers):\n",
    "    \n",
    "    # list to store follower\n",
    "    lst = []\n",
    "    \n",
    "    for profile in names:\n",
    "        lst.append(extracting_followers(driver, profile, no_of_followers))\n",
    "        time.sleep(3)\n",
    "        \n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conversion from string to int as in instgram\n",
    "\n",
    "def string_int(string):\n",
    "    \n",
    "    total = \"\"\n",
    "    num = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    for i in string:\n",
    "        if i in num:\n",
    "            total += i\n",
    "    total = int(total)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting all followers of a profile \n",
    "\n",
    "def extracting_all_followers(driver, profile, username, no_of_followers = 1000):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)              ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## clicking on followers\n",
    "    path = '//li[contains(@class, \"Y8-fY\")][2]/a'\n",
    "    followers = wait.until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "    followers.click()\n",
    "        \n",
    "    ## Extracting The No_of_followers\n",
    "    path = '//div[@class = \"PZuss\"]//li'\n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "    string =driver.find_elements_by_xpath(\"//span[contains(@class, 'g47SY')]\")[1].get_attribute(\"title\") \n",
    "    \n",
    "    ## integer total followers\n",
    "    total = string_int(string)\n",
    "    \n",
    "    ## Extracting followers\n",
    "    for i in range((total//2)+1):\n",
    "        scr1 = driver.find_element_by_xpath('/html/body/div[4]/div/div[2]')            ## followers window\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scr1)            ## Scrolling\n",
    "        time.sleep(3)\n",
    "        btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "        if(len(btn) >= no_of_followers):\n",
    "            break\n",
    "        \n",
    "    print(\"number of followers extracted of\", profile ,\":\", len(btn))\n",
    "        \n",
    "    pg = driver.page_source\n",
    "    data = bs4.BeautifulSoup(pg,\"lxml\")\n",
    "    user = data.find_all(\"a\",{\"class\":\"FPmhX\"})\n",
    "    \n",
    "    ## making the list\n",
    "    followers_ = []\n",
    "    for temp in user:\n",
    "        if temp.text == username:\n",
    "            continue\n",
    "        followers_.append(temp.text)   ## making a pair list\n",
    "        \n",
    "    ## exiting the followers page\n",
    "    btn = driver.find_element_by_class_name(\"wpO6b \")\n",
    "    btn.click()\n",
    "        \n",
    "    ## return to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return followers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting the following person username\n",
    "\n",
    "def extracting_all_following(driver, profile, username):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)              ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    ## clicking on followers\n",
    "    path = '//li[contains(@class, \"Y8-fY\")][3]/a'\n",
    "    following = wait.until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "    following.click()\n",
    "        \n",
    "    ## Extracting The No_of_followers\n",
    "    path = '//div[@class = \"PZuss\"]//li'\n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))\n",
    "    string = driver.find_elements_by_xpath(\"//span[contains(@class, 'g47SY')]\")[1].get_attribute(\"title\") \n",
    "    \n",
    "    ## integer total following\n",
    "    total = string_int(string)\n",
    "    \n",
    "    ## Extracting followings\n",
    "    for i in range((total//2)+1):\n",
    "        scr1 = driver.find_element_by_xpath('/html/body/div[4]/div/div[2]')            ## following window\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scr1)            ## Scrolling\n",
    "    \n",
    "    btn = wait.until(EC.presence_of_all_elements_located((By.XPATH,path)))    \n",
    "    print(\"number of followings extracted of\", profile ,\":\", len(btn))\n",
    "        \n",
    "    pg = driver.page_source\n",
    "    data = bs4.BeautifulSoup(pg,\"lxml\")\n",
    "    user = data.find_all(\"a\",{\"class\":\"FPmhX\"})\n",
    "    \n",
    "    ## making the list\n",
    "    followings_ = []\n",
    "    for temp in user:\n",
    "        if temp.text == username:\n",
    "            continue\n",
    "        followings_.append(temp.text)   ## making a pair list\n",
    "        \n",
    "    ## exiting the followers page\n",
    "    btn = driver.find_element_by_class_name(\"wpO6b \")\n",
    "    btn.click()\n",
    "        \n",
    "    ## return to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "    \n",
    "    return followings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the list of followers who follow the profile and the user follow them but they dont follow the user\n",
    "\n",
    "def followers_follow_profile_not_mine(driver, profiles):\n",
    "    \n",
    "    # list to store follower\n",
    "    lst = []    \n",
    "    \n",
    "    profile_followers = extracting_all_followers(driver, profiles[1], profiles[0])   ## considering 1000\n",
    "    my_followers = extracting_all_followers(driver, profiles[0], profile[0])  \n",
    "    my_following = extracting_all_following(driver, profiles[0], profiles[0])\n",
    "    \n",
    "    ## filteration\n",
    "    for i in my_following:\n",
    "        if (i[0] not in my_followers) and (i[0] in profile_followers):\n",
    "            lst.append(i[0])\n",
    "            \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of followers extracted of sodelhi : 504\n",
      "number of followers extracted of foodtalkindia : 504\n",
      "sodelhi followers:\n",
      "1 .  shivangi.sweet28\n",
      "2 .  gangesh.singh.5473\n",
      "3 .  ritakshishar\n",
      "4 .  rituka.agarwal\n",
      "5 .  itanishqwadhwa\n",
      "6 .  kkvinodkumar0017\n",
      "7 .  vohra7433\n",
      "8 .  moreliketravelling\n",
      "9 .  naman_9_24\n",
      "10 .  srishh__tea\n",
      "11 .  rajivikki\n",
      "12 .  anand_siwan\n",
      "13 .  harshitpandit362\n",
      "14 .  mr_khushal.singh\n",
      "15 .  kankit08\n",
      "16 .  asim_hussain__786\n",
      "17 .  nijrabizahab\n",
      "18 .  _sheena.bhatia_\n",
      "19 .  yamini.singh.12720\n",
      "20 .  alishaa.sharma\n",
      "21 .  anubhavagr27\n",
      "22 .  anush.103\n",
      "23 .  kush_chhaya\n",
      "24 .  journeysnbeyond\n",
      "25 .  sarvendrakumarsavendra\n",
      "26 .  1130sahil\n",
      "27 .  ankit_chahal_117\n",
      "28 .  vsquadpromotions\n",
      "29 .  me_dixit_bishwas\n",
      "30 .  zenabkebabsnkurries\n",
      "31 .  tejasri_mahija\n",
      "32 .  _md_ishan_\n",
      "33 .  aayushsahanan\n",
      "34 .  somya_doneria\n",
      "35 .  iamkritikaguptaa\n",
      "36 .  khidkitod_zindagi\n",
      "37 .  negipooja002\n",
      "38 .  foodie_indian.0\n",
      "39 .  aashnashewani\n",
      "40 .  goyal0103\n",
      "41 .  kanishq_besoya_dilli001\n",
      "42 .  mks4003\n",
      "43 .  vanshika_bansal840\n",
      "44 .  pratyush_raturi\n",
      "45 .  shikha_aggarwal2k18\n",
      "46 .  kshamasharma_21\n",
      "47 .  iamartichauhan\n",
      "48 .  aparnachopra\n",
      "49 .  _rupanshi_s\n",
      "50 .  prachisharma9958\n",
      "51 .  ramanbhalla83\n",
      "52 .  nishantchaudhary121\n",
      "53 .  _luda10luda_\n",
      "54 .  parminderkaur_24\n",
      "55 .  akan_3999\n",
      "56 .  officalhumansofdelhincr\n",
      "57 .  irvsharma\n",
      "58 .  simi_saini222\n",
      "59 .  clicksforcause\n",
      "60 .  kritikasehrawat296\n",
      "61 .  charvi.singhal\n",
      "62 .  janhavi_0\n",
      "63 .  preetikassal\n",
      "64 .  asif6909khan\n",
      "65 .  yesicaughtthetrain\n",
      "66 .  manikadayal\n",
      "67 .  _malik.shreya_\n",
      "68 .  pravakarch\n",
      "69 .  san_sanjana._\n",
      "70 .  abhishek4treck\n",
      "71 .  vermasheetaljoshi\n",
      "72 .  kinzalsharmaa\n",
      "73 .  ___aranyaar_dinraatri___\n",
      "74 .  amirziddi\n",
      "75 .  shivadadhwal\n",
      "76 .  rajeshrai6007\n",
      "77 .  anubhaa_arora\n",
      "78 .  joaoaugustooc\n",
      "79 .  bhumising27\n",
      "80 .  hiteshkhanna63\n",
      "81 .  riyaag7\n",
      "82 .  ishika3603\n",
      "83 .  arshitaaneja\n",
      "84 .  i_pvt_\n",
      "85 .  maryam_0421\n",
      "86 .  abedinmimhajul\n",
      "87 .  letsgetspooned\n",
      "88 .  the.ashis.jain\n",
      "89 .  anishachugh19\n",
      "90 .  food.barbqd\n",
      "91 .  sumansingh15001\n",
      "92 .  arpit.chhabra_\n",
      "93 .  shweta_99588\n",
      "94 .  anjali_yadav_5211\n",
      "95 .  karsohail100\n",
      "96 .  utkarshsharma9818\n",
      "97 .  amittsoni97\n",
      "98 .  bhawna.s.tanwar\n",
      "99 .  bhumi_singha\n",
      "100 .  pakhi_001\n",
      "101 .  mehak.rt\n",
      "102 .  zehan_mirza\n",
      "103 .  vatsalabhardwaj_\n",
      "104 .  sachingujjar0193\n",
      "105 .  omkarpatilmusic\n",
      "106 .  deekshitabarnwal\n",
      "107 .  ashutoshasthana.writer\n",
      "108 .  iamarushimehta\n",
      "109 .  aradhya_098\n",
      "110 .  vishwakarmasubhi\n",
      "111 .  ishakaurmua\n",
      "112 .  rashigupta_16\n",
      "113 .  ifoodiesoul\n",
      "114 .  creative1arts\n",
      "115 .  deepali_sam\n",
      "116 .  santoshsanath\n",
      "117 .  agarwalsanskruti\n",
      "118 .  sq6523470\n",
      "119 .  anveerrahman\n",
      "120 .  shivamawasthi38\n",
      "121 .  chivy_57\n",
      "122 .  satyaveer6814\n",
      "123 .  thatmoodychild\n",
      "124 .  ashu007garg\n",
      "125 .  _djani_19\n",
      "126 .  himanshu1347\n",
      "127 .  richa_rnm\n",
      "128 .  jha_shaeb\n",
      "129 .  ori_on8\n",
      "130 .  sonalsinghal11\n",
      "131 .  _be_classy_be_maddy_\n",
      "132 .  vvipabhishekpandat\n",
      "133 .  crazzychidiyaa\n",
      "134 .  komu991\n",
      "135 .  himavandahiya\n",
      "136 .  ramanarora24\n",
      "137 .  lalita.parihar\n",
      "138 .  akash4917\n",
      "139 .  foodofoodie\n",
      "140 .  abhay_93\n",
      "141 .  diksha__chandra\n",
      "142 .  niteshsingh4571\n",
      "143 .  singhalsudha\n",
      "144 .  lone_travellerrr\n",
      "145 .  gupta_sumit1109\n",
      "146 .  sabiha.beig\n",
      "147 .  vegnfruit01\n",
      "148 .  nancygupta7\n",
      "149 .  kaif_king001\n",
      "150 .  anankit4u\n",
      "151 .  evidence_of_explorer\n",
      "152 .  _loyalliar\n",
      "153 .  ask_subbu\n",
      "154 .  himanshirawat13\n",
      "155 .  sachin.gupta28\n",
      "156 .  its_mr.sachin_gautam\n",
      "157 .  ankurjainaj22\n",
      "158 .  _liquidsunsets_\n",
      "159 .  tauseef8232\n",
      "160 .  adinremahk\n",
      "161 .  k2krishika\n",
      "162 .  itzs__chanchal\n",
      "163 .  sabharwal138\n",
      "164 .  simpal_man_2002\n",
      "165 .  _jaskiran._\n",
      "166 .  smit22653\n",
      "167 .  ashwinranjansingh\n",
      "168 .  kishika_chopra\n",
      "169 .  ig_47deepak\n",
      "170 .  mephistopheles.24\n",
      "171 .  badshahkhan3181\n",
      "172 .  shanti_pradhan10\n",
      "173 .  _mehak7678_\n",
      "174 .  chefabhishekgupta\n",
      "175 .  navneetveerpal99\n",
      "176 .  meghaverma731\n",
      "177 .  arpan__toppo\n",
      "178 .  photographersahab\n",
      "179 .  thisispaulpage\n",
      "180 .  dilli_foodiz\n",
      "181 .  patel_._purvi\n",
      "182 .  vinny_23nov\n",
      "183 .  maahii3329\n",
      "184 .  witness_of_myself\n",
      "185 .  akankshasdiary\n",
      "186 .  honeyaryo\n",
      "187 .  ledy_an51\n",
      "188 .  ayye.ess\n",
      "189 .  portraying_india\n",
      "190 .  rachit.mehta1010\n",
      "191 .  merazaliazhari786\n",
      "192 .  puipuiiii_99\n",
      "193 .  gurpreet9817singh9\n",
      "194 .  dhanashreereddy\n",
      "195 .  9092sameer\n",
      "196 .  fiza6235\n",
      "197 .  rae__za\n",
      "198 .  sagargoswami9297\n",
      "199 .  pixe.d\n",
      "200 .  pt.sourabhshastri\n",
      "201 .  manojgiri080_mj\n",
      "202 .  radha6876\n",
      "203 .  sak.shiiiiiii\n",
      "204 .  _aasthaagrawal\n",
      "205 .  _lensoul_\n",
      "206 .  __uknowme.__\n",
      "207 .  escaping_tales\n",
      "208 .  cohnda\n",
      "209 .  kanikaxsharma_\n",
      "210 .  khangurl_\n",
      "211 .  _shubhamgoel\n",
      "212 .  kaiser.kumar\n",
      "213 .  devaanand00\n",
      "214 .  khushi_shah_99\n",
      "215 .  97_jack_sparrow\n",
      "216 .  bachchaspiyush\n",
      "217 .  pal_pal_dil_kepaas\n",
      "218 .  dark.phoenixstudios\n",
      "219 .  sajith7245\n",
      "220 .  anannyachakraborty\n",
      "221 .  jeewanrajendersingh\n",
      "222 .  kumarmr.shubham\n",
      "223 .  pranavaspakala\n",
      "224 .  rohansalvi93\n",
      "225 .  rolling_royces\n",
      "226 .  _mitali_saini_02\n",
      "227 .  aadityasingh54\n",
      "228 .  ri_adhikari\n",
      "229 .  kanakvyas\n",
      "230 .  sumitkapoor_91\n",
      "231 .  prachijain2587\n",
      "232 .  nandram0388\n",
      "233 .  anshu_makhija8\n",
      "234 .  mittalisaxena\n",
      "235 .  aparna.agarwal06\n",
      "236 .  mannrohit147\n",
      "237 .  shreysrawat\n",
      "238 .  rashaniyagautam\n",
      "239 .  sachin8249\n",
      "240 .  mishrakanksha27\n",
      "241 .  khushboo.goenka\n",
      "242 .  shwarmajii\n",
      "243 .  jeepvt\n",
      "244 .  rajrajvashisht\n",
      "245 .  alok_the_scorpion_king\n",
      "246 .  glammmebymk\n",
      "247 .  _error404_ntfound\n",
      "248 .  i_shanky08\n",
      "249 .  kunnal_bhatia\n",
      "250 .  seovirtualassistant\n",
      "251 .  chakshanigoyal\n",
      "252 .  rakeshpandey358\n",
      "253 .  i_am_the_line_beneath\n",
      "254 .  aryan___gupta\n",
      "255 .  d_k.love_1623\n",
      "256 .  saurav_joshi27\n",
      "257 .  akanshadhaiya\n",
      "258 .  shailendra.singh.1213\n",
      "259 .  thepartymantra\n",
      "260 .  __heartbroker__2\n",
      "261 .  ju_ju_03\n",
      "262 .  biryanistudio\n",
      "263 .  usmanhq\n",
      "264 .  immanuel_sisira\n",
      "265 .  jayp861\n",
      "266 .  guramrit_singh12\n",
      "267 .  de.epika9965\n",
      "268 .  jdgjhu\n",
      "269 .  piyush.roongta24\n",
      "270 .  shahnawazansari940\n",
      "271 .  alloinnoware\n",
      "272 .  sajad_75d\n",
      "273 .  delhi_foodstories\n",
      "274 .  _vidhi_jain_10\n",
      "275 .  vk19_97\n",
      "276 .  simply.stupid101\n",
      "277 .  saurabhsrivastava446\n",
      "278 .  naren4669\n",
      "279 .  garimaupreti\n",
      "280 .  chaitanya.51\n",
      "281 .  travelnfoodstories\n",
      "282 .  desk.aa012\n",
      "283 .  beansahabcafe\n",
      "284 .  milanbairwa27\n",
      "285 .  _.srt._8055\n",
      "286 .  thevarunpathak\n",
      "287 .  metrosandmomos\n",
      "288 .  shreashh_\n",
      "289 .  drishtishah_\n",
      "290 .  luv_singh_13\n",
      "291 .  loly.2937\n",
      "292 .  i_am_rehan_0787\n",
      "293 .  _inshaiqbal\n",
      "294 .  kewaleeiskewalee\n",
      "295 .  sharmajikaladka10\n",
      "296 .  excelsior2921\n",
      "297 .  aksajaved\n",
      "298 .  30.maar.khan\n",
      "299 .  vrushali_choudhari\n",
      "300 .  lifeisbeautiful_yashika\n",
      "301 .  sahilxsachdeva\n",
      "302 .  devender.kumar.56614\n",
      "303 .  roesieaa\n",
      "304 .  gannetgirls\n",
      "305 .  arnabhbx\n",
      "306 .  kaifrizvimohd\n",
      "307 .  mittalibharti\n",
      "308 .  habibi_shawarma\n",
      "309 .  poyo_eat\n",
      "310 .  shabbyy270\n",
      "311 .  bishtj591\n",
      "312 .  aarti6010\n",
      "313 .  babli61\n",
      "314 .  anshul8724\n",
      "315 .  indiiganza\n",
      "316 .  00maytas00\n",
      "317 .  prashantsindhav98\n",
      "318 .  manujsharma2020\n",
      "319 .  ragz.dubey\n",
      "320 .  nupursingh_20\n",
      "321 .  hemalatasahu\n",
      "322 .  facts_to_view\n",
      "323 .  sathidevsoni\n",
      "324 .  girlasset\n",
      "325 .  nadeemsaifi2111\n",
      "326 .  md.fareed.9693\n",
      "327 .  nazarul.khan.775\n",
      "328 .  monicasawhney\n",
      "329 .  vikasmalik510\n",
      "330 .  swatibg1\n",
      "331 .  param.verma.14224\n",
      "332 .  shub1394\n",
      "333 .  ashishhhh.verma\n",
      "334 .  shobhit___jain\n",
      "335 .  official_benipal46\n",
      "336 .  dvysia\n",
      "337 .  abd_el_bari_sw\n",
      "338 .  _anuakki\n",
      "339 .  2000_i_k\n",
      "340 .  only_aisha_\n",
      "341 .  ravirajput5378\n",
      "342 .  7_rishabhjain\n",
      "343 .  positivevibes675\n",
      "344 .  sainimuskaan\n",
      "345 .  kajalwadhwa\n",
      "346 .  kushchakravarty\n",
      "347 .  varuna__saini\n",
      "348 .  tanviyasmin\n",
      "349 .  delhi6558\n",
      "350 .  raysrishti\n",
      "351 .  the_completemess\n",
      "352 .  kajalshrivastav15\n",
      "353 .  mariyamkhan____\n",
      "354 .  puru9650\n",
      "355 .  annkit_24\n",
      "356 .  shubhamjangir532\n",
      "357 .  gauravg097\n",
      "358 .  kevinthomasx\n",
      "359 .  abhi.4u\n",
      "360 .  adityasharmah\n",
      "361 .  garimaxsharma\n",
      "362 .  thehiddencrest\n",
      "363 .  nikitaagarwal30\n",
      "364 .  surbhijain333\n",
      "365 .  millennialtrotter\n",
      "366 .  p.silove\n",
      "367 .  ananiakhidaya\n",
      "368 .  loving_devil3\n",
      "369 .  alfaz_hi_alfaz\n",
      "370 .  diyaasinglaa\n",
      "371 .  gurvysidhu\n",
      "372 .  angela_stephen_\n",
      "373 .  ankitraj10a\n",
      "374 .  chandni.khemani.13\n",
      "375 .  glamfacesbyshailjagupta\n",
      "376 .  rs23182632019\n",
      "377 .  adilkashish\n",
      "378 .  urdad706\n",
      "379 .  nadeem_malik_model_\n",
      "380 .  durgesha_now\n",
      "381 .  manjeet_antil_1\n",
      "382 .  khan_aleena21\n",
      "383 .  sahil__rajpal\n",
      "384 .  ritesh_ritzs_\n",
      "385 .  pinki.sangwan.33\n",
      "386 .  delhilaserclinic\n",
      "387 .  vanshikabhat_\n",
      "388 .  radhikatayal02\n",
      "389 .  theshreykarkhur\n",
      "390 .  piankayadav\n",
      "391 .  asha.bhatia.39108\n",
      "392 .  prabhat_kishore\n",
      "393 .  lazy_br0wn_bird27\n",
      "394 .  _anjali_jha1811\n",
      "395 .  kkkaa2020\n",
      "396 .  ishikaagarwal2891\n",
      "397 .  antidote_nidhi\n",
      "398 .  parullmakeoverrs\n",
      "399 .  sanyasinghal\n",
      "400 .  kunalmishra367\n",
      "401 .  ridhigulati12\n",
      "402 .  nn2805\n",
      "403 .  gunjan_sadh_\n",
      "404 .  gagan._.ludhiana\n",
      "405 .  jisin.chirayath\n",
      "406 .  klokesh_\n",
      "407 .  simran.__khurana\n",
      "408 .  swekritimathur\n",
      "409 .  vikasbhalla12\n",
      "410 .  its.gross\n",
      "411 .  ricky._.goyal\n",
      "412 .  _sanjana_joshi_\n",
      "413 .  sam_sidd5\n",
      "414 .  jin.chauhan\n",
      "415 .  gurleenn__kaurr\n",
      "416 .  abishak.gupta.1044\n",
      "417 .  shi.v.aay\n",
      "418 .  singhkartar289\n",
      "419 .  vikasosmium\n",
      "420 .  im.adi.27\n",
      "421 .  saif.aksha\n",
      "422 .  jatin_09s\n",
      "423 .  vishakha.garg\n",
      "424 .  metamorphosisbyshaliniac\n",
      "425 .  dikshita_garg\n",
      "426 .  jyoti.ch13.10\n",
      "427 .  tapan_zena\n",
      "428 .  its.ishan\n",
      "429 .  simrannarula05\n",
      "430 .  anjali.kunu\n",
      "431 .  aakash.7599\n",
      "432 .  aditya.2082\n",
      "433 .  sharma_kartik_\n",
      "434 .  nayyonika_\n",
      "435 .  meenu_deenu_sheoran\n",
      "436 .  sahilkatariaa\n",
      "437 .  _mrdorvi_\n",
      "438 .  theaditishah_\n",
      "439 .  tanujakaushik_107\n",
      "440 .  that.brown.girl_\n",
      "441 .  _alma_ali_\n",
      "442 .  its_me_yashashh\n",
      "443 .  shivangigoel7466\n",
      "444 .  rimpi19sarma\n",
      "445 .  awesome_swagger_267\n",
      "446 .  xx.aiman\n",
      "447 .  priya_nkapatwa\n",
      "448 .  sharayu_dalvi\n",
      "449 .  _harshit.grover_\n",
      "450 .  dev_db\n",
      "451 .  witty_boiii\n",
      "452 .  isharastogi019\n",
      "453 .  sameer_saurabh116\n",
      "454 .  gaurvipasha\n",
      "455 .  prashasti._saxena\n",
      "456 .  ar.saurabh.dhamija\n",
      "457 .  _palakkanojia_\n",
      "458 .  ronit_008\n",
      "459 .  freckled_face1808\n",
      "460 .  sinskaarisisters\n",
      "461 .  1718mahi\n",
      "462 .  nabiya__feroz\n",
      "463 .  foodliners\n",
      "464 .  _fypo_\n",
      "465 .  somya_sachdeva_\n",
      "466 .  richadhruvc\n",
      "467 .  abhay_om\n",
      "468 .  gagan_the_messy_head\n",
      "469 .  radhika.ride\n",
      "470 .  roshni.gariya\n",
      "471 .  wannabe_maverick\n",
      "472 .  prkpaow\n",
      "473 .  confessionsdelhimetro\n",
      "474 .  parivagupta\n",
      "475 .  himanshusharma3191\n",
      "476 .  vaibhavjain591\n",
      "477 .  dhruv.kalraa\n",
      "478 .  its_meenukushwaha\n",
      "479 .  yoeeswaraiah\n",
      "480 .  thulasi__sivakumar\n",
      "481 .  rajeshwari_pandey_\n",
      "482 .  manpreet_4980\n",
      "483 .  saanchi_gupta\n",
      "484 .  mobile__photography200\n",
      "485 .  y_o_g_e_s_h_2_5\n",
      "486 .  ngrewalll_0409\n",
      "487 .  mr._king_s_sahay\n",
      "488 .  manuhajela\n",
      "489 .  radvisionworldconsultancy\n",
      "490 .  reeviya_singh\n",
      "491 .  divyakrishna593\n",
      "492 .  tush_narula\n",
      "493 .  rajkumarpurve\n",
      "494 .  sethi529\n",
      "495 .  thethinker_24\n",
      "496 .  silentknight_007\n",
      "497 .  s.o.n.a.l\n",
      "498 .  harsh_parvani5555\n",
      "499 .  vishal__24\n",
      "500 .  sanyathisside\n",
      "\n",
      "foodtalkindia followers:\n",
      "1 .  dekanivashree\n",
      "2 .  atifmokim\n",
      "3 .  cramphul\n",
      "4 .  ishika_.12\n",
      "5 .  khushboorathor567\n",
      "6 .  mu_skan1079\n",
      "7 .  omkar.pawar.18\n",
      "8 .  pratikshasangwan_\n",
      "9 .  dr.sumitkumar\n",
      "10 .  abualknane\n",
      "11 .  mee.5253\n",
      "12 .  urooj_ayub_v\n",
      "13 .  mradulah\n",
      "14 .  delusion_of_creatives\n",
      "15 .  vinaykmr824\n",
      "16 .  alynazafarr\n",
      "17 .  aishwary_r98\n",
      "18 .  eleni_vrahnos\n",
      "19 .  karan_bhawnani\n",
      "20 .  sbmkolhe\n",
      "21 .  rinijain0\n",
      "22 .  alejam_23\n",
      "23 .  gastronaut_ripan\n",
      "24 .  __anwesh__20\n",
      "25 .  amirherry\n",
      "26 .  _mjdolly\n",
      "27 .  kittyhasadream\n",
      "28 .  e_l_i_s_h_a______________\n",
      "29 .  ramanbhalla83\n",
      "30 .  umee_aiman01\n",
      "31 .  d_dsouzamepprath\n",
      "32 .  shivanirajput0027\n",
      "33 .  officalhumansofdelhincr\n",
      "34 .  shurjopov\n",
      "35 .  dannyboy5590\n",
      "36 .  oussenichaima\n",
      "37 .  brewedmalt\n",
      "38 .  supratik_p\n",
      "39 .  truptifoodstyling\n",
      "40 .  sahithc_reddy\n",
      "41 .  tripathyalka\n",
      "42 .  marylin_aiello04\n",
      "43 .  letsgetspooned\n",
      "44 .  amanyaprism\n",
      "45 .  emran_wani\n",
      "46 .  rohit.nagpal999\n",
      "47 .  amitkumar2801\n",
      "48 .  raaz___azmi\n",
      "49 .  umasaraf_bittu\n",
      "50 .  viruu00\n",
      "51 .  cafedurgabhosari\n",
      "52 .  yulin.esm\n",
      "53 .  tanisharanaofficial\n",
      "54 .  bhavyasoni_\n",
      "55 .  foodie_crush26\n",
      "56 .  snow_world_princess\n",
      "57 .  kuumbkarran\n",
      "58 .  guptashivani09\n",
      "59 .  rahilanoor100\n",
      "60 .  sinskaarisisters\n",
      "61 .  omkarpatilmusic\n",
      "62 .  realfood_people\n",
      "63 .  iawadhi\n",
      "64 .  madhuriholey\n",
      "65 .  rekhashakya1994\n",
      "66 .  shan_aya0001\n",
      "67 .  anushkatulsani\n",
      "68 .  diti_saini\n",
      "69 .  ifoodiesoul\n",
      "70 .  ohh_god_y\n",
      "71 .  arijitownsit\n",
      "72 .  stylishboy8990\n",
      "73 .  su30_mki\n",
      "74 .  piya5783\n",
      "75 .  vaish.wishes\n",
      "76 .  agarwalsejal\n",
      "77 .  heermusic\n",
      "78 .  khalidtabrez99\n",
      "79 .  anjaligoyal8624\n",
      "80 .  abhijot_sandhu\n",
      "81 .  sumkuborah\n",
      "82 .  jaibansal9\n",
      "83 .  paratha.inn\n",
      "84 .  ravichamarthy\n",
      "85 .  gj3rajkot\n",
      "86 .  roops710\n",
      "87 .  capturedelight\n",
      "88 .  tirupati_group\n",
      "89 .  rishi_unknown_420\n",
      "90 .  maersh_mellow\n",
      "91 .  murginns\n",
      "92 .  peacfully_chaotic\n",
      "93 .  __nehaha___\n",
      "94 .  shoeib_shk_70\n",
      "95 .  shivangi.19\n",
      "96 .  dr.deepankar05\n",
      "97 .  madhumrita_madhavi_devi_dasi\n",
      "98 .  kekizdelhi\n",
      "99 .  thefridayay_man\n",
      "100 .  tds_the_delicious_spread\n",
      "101 .  landgesaziya\n",
      "102 .  srispeaks\n",
      "103 .  sakshiiii_arora\n",
      "104 .  hitesh_panchariya\n",
      "105 .  jhalli_billi\n",
      "106 .  vindu30\n",
      "107 .  akankshasdiary\n",
      "108 .  explore.beautyof.india\n",
      "109 .  mr.peace_2004\n",
      "110 .  abhishekanandphotography\n",
      "111 .  mr_mentalist__\n",
      "112 .  ideator_raj\n",
      "113 .  m_c_royal_8477\n",
      "114 .  ajaytheshaukeen\n",
      "115 .  foodiesinthetown\n",
      "116 .  samirkumar3636\n",
      "117 .  blissful100years\n",
      "118 .  mr.vip_cctv\n",
      "119 .  pavan_dalvi\n",
      "120 .  sajith7245\n",
      "121 .  sanam.rox\n",
      "122 .  yukalyptis\n",
      "123 .  jeewanrajendersingh\n",
      "124 .  rolling_royces\n",
      "125 .  dish_on_that_table\n",
      "126 .  kangscookingcorner\n",
      "127 .  khushpalsingh_sindrath\n",
      "128 .  jitendrajaiswal1967\n",
      "129 .  skin.shades\n",
      "130 .  bhookh_lagi\n",
      "131 .  gandhipd15\n",
      "132 .  devendra8582\n",
      "133 .  just.food.everytime7\n",
      "134 .  veekasjain\n",
      "135 .  _the_curly_whirly_\n",
      "136 .  abdullah.faiz.3363\n",
      "137 .  eats_and_treats__\n",
      "138 .  thepartymantra\n",
      "139 .  fateh.gill._\n",
      "140 .  khwajaumnar\n",
      "141 .  __king__of__attitude\n",
      "142 .  rajputs_recipe\n",
      "143 .  ___attitude__lover___\n",
      "144 .  jtprateek\n",
      "145 .  reshma.kamble.3150807\n",
      "146 .  findkanpur\n",
      "147 .  born__kaur\n",
      "148 .  foodl.ve\n",
      "149 .  nuzhat_khaan\n",
      "150 .  jiudaan_bty\n",
      "151 .  truptisamantara\n",
      "152 .  shifanmazi\n",
      "153 .  diyashonai6\n",
      "154 .  rekhasingh209\n",
      "155 .  tanvipahwa1988\n",
      "156 .  _inaman03\n",
      "157 .  shahi_farhana_tasnim_aj\n",
      "158 .  savinashkumar\n",
      "159 .  thetrillionfood\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 .  vrushali_choudhari\n",
      "161 .  krinaltank\n",
      "162 .  boby_sid_786\n",
      "163 .  poyo_eat\n",
      "164 .  foodoholic27\n",
      "165 .  chef_surendra_singh\n",
      "166 .  svdvvishan\n",
      "167 .  hungerstrike2\n",
      "168 .  mayank_5366\n",
      "169 .  siddharthjain_55\n",
      "170 .  innocent_insane21\n",
      "171 .  official_benipal46\n",
      "172 .  bowl.story\n",
      "173 .  mohnishkaur\n",
      "174 .  memes__guru_\n",
      "175 .  captain_looney__\n",
      "176 .  amit__keer\n",
      "177 .  gujartejas\n",
      "178 .  ruchisiddhpura\n",
      "179 .  jovanmartins\n",
      "180 .  falak__04\n",
      "181 .  umbrook77\n",
      "182 .  _shalini_ss7\n",
      "183 .  vasanth_macho\n",
      "184 .  anakapu1\n",
      "185 .  foodyniks\n",
      "186 .  phailja\n",
      "187 .  aniket.chauhan.1654\n",
      "188 .  bhat.shakir.790693\n",
      "189 .  nenugala\n",
      "190 .  kimsara.official\n",
      "191 .  itsmeshefeeq\n",
      "192 .  _rubberrrbandd_\n",
      "193 .  pandit.yara\n",
      "194 .  sohel_polutry_farm\n",
      "195 .  enigmatic___guy\n",
      "196 .  _san.ia._\n",
      "197 .  artingoutloud\n",
      "198 .  fernandaramos3953\n",
      "199 .  saansh_shetty10\n",
      "200 .  mr.imran_008\n",
      "201 .  gkhurana27\n",
      "202 .  aapllkarad\n",
      "203 .  rohitt_pioneer\n",
      "204 .  barbie__rawat\n",
      "205 .  iamshubham._.1703\n",
      "206 .  shivangikashyap694\n",
      "207 .  a_p_p_i_e_e\n",
      "208 .  reyansh8673\n",
      "209 .  kiarita_2115\n",
      "210 .  aamittandon\n",
      "211 .  theqcoderestaurant\n",
      "212 .  jyoti_makwana1492\n",
      "213 .  smithzahion\n",
      "214 .  adityachhaparwal\n",
      "215 .  its.ishan\n",
      "216 .  outofthebluebombay\n",
      "217 .  foodsafetygenie\n",
      "218 .  poozaa_louis\n",
      "219 .  kalsisimrawn\n",
      "220 .  kripatudu\n",
      "221 .  fatimah.jameel\n",
      "222 .  govindpandat97\n",
      "223 .  street_foodindia\n",
      "224 .  runner_underdog\n",
      "225 .  ____muskandharma____\n",
      "226 .  foodieimmigrant\n",
      "227 .  samitaphusam\n",
      "228 .  themby_c_cakes\n",
      "229 .  _coleeeeen_\n",
      "230 .  flavourcatcher\n",
      "231 .  rupali_fadtare\n",
      "232 .  hungry.voyagers\n",
      "233 .  shaunakirkire\n",
      "234 .  akanshasoni_\n",
      "235 .  pawanshelke70\n",
      "236 .  zaid_siddiqui1122\n",
      "237 .  akssindia\n",
      "238 .  hotelmidtownpritam\n",
      "239 .  5feet4_designstudio\n",
      "240 .  furqanhyder96\n",
      "241 .  sonal.gupta26\n",
      "242 .  runaway_foodies\n",
      "243 .  vanishagambhir\n",
      "244 .  onepointdestinationishere\n",
      "245 .  delishd_\n",
      "246 .  varsad_drj\n",
      "247 .  ruchi5049\n",
      "248 .  nites_h___\n",
      "249 .  heartstocker\n",
      "250 .  the_treehouse_jibhi\n",
      "251 .  nancy._2145\n",
      "252 .  rishi_0591\n",
      "253 .  yummy_tummy217\n",
      "254 .  thedroolfactory_\n",
      "255 .  rrppinsta\n",
      "256 .  shekhawatpari\n",
      "257 .  vartulchawla\n",
      "258 .  deepanarun\n",
      "259 .  abbubakkasiddiq\n",
      "260 .  cinnamonhakuraahuraa\n",
      "261 .  vadheladipak57\n",
      "262 .  chhipa__yasu\n",
      "263 .  __kiran__sharma__10496__\n",
      "264 .  alvia_siddiqui05\n",
      "265 .  kushwaha2150\n",
      "266 .  mayu_burhade\n",
      "267 .  food_storiesbyhaimanti\n",
      "268 .  sribhuvana\n",
      "269 .  akiri_nikithaaaaaaa\n",
      "270 .  jsosa_24\n",
      "271 .  chef3137\n",
      "272 .  bhavnasingh24\n",
      "273 .  diary_of_a_bengaluru_foodie\n",
      "274 .  eswar079\n",
      "275 .  naseemlawrencenautiyal\n",
      "276 .  nehajdevkar\n",
      "277 .  seemajaiswal301\n",
      "278 .  riasarin4\n",
      "279 .  nishajadhav691\n",
      "280 .  sneh_lata\n",
      "281 .  i_am_sufiya_siddiqui\n",
      "282 .  payalkaundal\n",
      "283 .  __yashodhan\n",
      "284 .  ajeetsingh000\n",
      "285 .  prateekkewalramani\n",
      "286 .  oksanghi\n",
      "287 .  vik.talwar\n",
      "288 .  hrithikghosh10\n",
      "289 .  murali_gmr\n",
      "290 .  official.mr_samir_memon_\n",
      "291 .  theroyalkitchenbali\n",
      "292 .  sg_lovely_bhaskar_g\n",
      "293 .  a_i_s_h_u_a_n_g_el_\n",
      "294 .  sumitmadhwal\n",
      "295 .  foodiesaniya\n",
      "296 .  babaguru16\n",
      "297 .  sajan_gill07\n",
      "298 .  jackofalllmasterofnone\n",
      "299 .  thairaomarjee\n",
      "300 .  sharmanamita\n",
      "301 .  tomtharakan\n",
      "302 .  anuchoudhary1979\n",
      "303 .  soft_touch_facility_management\n",
      "304 .  anewlike\n",
      "305 .  your_chosen_flavour\n",
      "306 .  larrycao\n",
      "307 .  nageshdhurve87\n",
      "308 .  george.sheeba\n",
      "309 .  the_midnight_tunes\n",
      "310 .  ashisharora7860\n",
      "311 .  _alinaaa14\n",
      "312 .  homecookfoodieeu\n",
      "313 .  xoxsm\n",
      "314 .  platinum_gemstones\n",
      "315 .  whitefang_ryan\n",
      "316 .  manohar_66\n",
      "317 .  kitchenfootstepsabad\n",
      "318 .  chefandreamura\n",
      "319 .  anu_anni14\n",
      "320 .  gratekitchen\n",
      "321 .  akhil_sajwan\n",
      "322 .  nayan_swetha11\n",
      "323 .  xx__pri__ya__xx\n",
      "324 .  yeskay_sk\n",
      "325 .  ayushkumarsingh96\n",
      "326 .  surrsh7\n",
      "327 .  sureshsirvisuresh342\n",
      "328 .  truetopalate\n",
      "329 .  zaikaofindia_\n",
      "330 .  egg__space\n",
      "331 .  soumya.g\n",
      "332 .  himeshmehtaphotography\n",
      "333 .  ashlesha_raval_\n",
      "334 .  theaimston\n",
      "335 .  indiakagome\n",
      "336 .  a.loner.wolf\n",
      "337 .  manu.thewriterer\n",
      "338 .  leaning_into_tastes\n",
      "339 .  nikita.sharma9625\n",
      "340 .  keepingupwithanshuu\n",
      "341 .  singhpratibha110_\n",
      "342 .  _sharvarishailesh_\n",
      "343 .  aadatan_fitoori\n",
      "344 .  _arjungautam\n",
      "345 .  house_of_foodie_\n",
      "346 .  moni_shravan\n",
      "347 .  nmishraoff\n",
      "348 .  raha.deen\n",
      "349 .  haresh_satvara99\n",
      "350 .  anokho_gujju99\n",
      "351 .  diariesoffoodie\n",
      "352 .  debnath4960\n",
      "353 .  001muskandedha\n",
      "354 .  imvedantchawla\n",
      "355 .  partypopsofficial\n",
      "356 .  apoorvasaxena112\n",
      "357 .  predator_shivam\n",
      "358 .  rakeshpatil2701\n",
      "359 .  rafco54\n",
      "360 .  art_is_soulfood\n",
      "361 .  dingdongbell_001\n",
      "362 .  doseofmess\n",
      "363 .  hemen.in\n",
      "364 .  sooraj_tha\n",
      "365 .  foood_hunterr\n",
      "366 .  nirvanakitchen_leuven\n",
      "367 .  deepaksaluja19\n",
      "368 .  ramsawroopjaat\n",
      "369 .  simwalia3\n",
      "370 .  lucky_singh_85\n",
      "371 .  glamourfacessmakeup\n",
      "372 .  puri.gunjan\n",
      "373 .  jassuorrphr\n",
      "374 .  _zombie_95\n",
      "375 .  franx_pvt\n",
      "376 .  _jatinverma_.007\n",
      "377 .  maheshsagale\n",
      "378 .  harshu_nagda\n",
      "379 .  sandeepsanju4340\n",
      "380 .  ritsingh0121\n",
      "381 .  the_usual_mess\n",
      "382 .  guru_rj_ofic\n",
      "383 .  iam_swagatikarouta\n",
      "384 .  konkan_kanyaaaa\n",
      "385 .  funac_count\n",
      "386 .  eaglea.m\n",
      "387 .  satishy33\n",
      "388 .  houseofsuccess_\n",
      "389 .  dimpletarun\n",
      "390 .  bangaloredumplingss\n",
      "391 .  zakirpathan1\n",
      "392 .  ankie6982\n",
      "393 .  kochharheena\n",
      "394 .  g1boss\n",
      "395 .  sanyaarora04\n",
      "396 .  keerthini_m\n",
      "397 .  nikkynagarkar\n",
      "398 .  prathyush_g\n",
      "399 .  chethanjay003\n",
      "400 .  nihar_lalpurwala\n",
      "401 .  dipuba_rana\n",
      "402 .  searockblr\n",
      "403 .  supriya_v28\n",
      "404 .  ewanskitchen\n",
      "405 .  _rinni1\n",
      "406 .  shailymehta15\n",
      "407 .  theclassthali\n",
      "408 .  revant.h_\n",
      "409 .  aish_james\n",
      "410 .  khaati_peeti_rach\n",
      "411 .  urban_elements5\n",
      "412 .  socho_sale_to_sell\n",
      "413 .  smita__003\n",
      "414 .  pavan.1234561\n",
      "415 .  foodolicious_1\n",
      "416 .  mumbaiditela\n",
      "417 .  nature._____.photography\n",
      "418 .  ranjantoppotoppo\n",
      "419 .  uma_ahirwar\n",
      "420 .  rk_rishu____rishu3690\n",
      "421 .  shray5555\n",
      "422 .  devika.bhateja\n",
      "423 .  sonampunjabi\n",
      "424 .  bhok_lagyoo\n",
      "425 .  singhnirman10\n",
      "426 .  caking_28\n",
      "427 .  abhishekgupta2780\n",
      "428 .  totan_chef\n",
      "429 .  chefsamrat\n",
      "430 .  _pavan_teli\n",
      "431 .  akshu_1322\n",
      "432 .  rashidhussain8717\n",
      "433 .  nagesh16\n",
      "434 .  mairanamu\n",
      "435 .  mr_faisu_777\n",
      "436 .  akshayvhanoli\n",
      "437 .  monikakwatra84\n",
      "438 .  devastating_devourer\n",
      "439 .  kesariyafrm\n",
      "440 .  crazysoul.26\n",
      "441 .  blu_etick\n",
      "442 .  dasaninditha\n",
      "443 .  sandeepekal\n",
      "444 .  re8593873\n",
      "445 .  stephen.rodrigues\n",
      "446 .  sangamithra18\n",
      "447 .  sha____hector\n",
      "448 .  anapvttt\n",
      "449 .  wishadishpos\n",
      "450 .  sanjay_versatile_\n",
      "451 .  mukesh.8870\n",
      "452 .  daiexpressionistmural\n",
      "453 .  eroda_7\n",
      "454 .  pratibha__rajput\n",
      "455 .  destination_hub_\n",
      "456 .  huvisumiswu\n",
      "457 .  olddelhicommunity\n",
      "458 .  kaurageous.harleen.1919\n",
      "459 .  travelinggfoodiee\n",
      "460 .  y__aag__nik\n",
      "461 .  abhishek.gupta97\n",
      "462 .  paktiktokofficial\n",
      "463 .  thekarigarsofindia\n",
      "464 .  bobby__gill\n",
      "465 .  iftikhar_ansari01\n",
      "466 .  _anjali\n",
      "467 .  dipster.786\n",
      "468 .  kharbandalisha23\n",
      "469 .  shades_of_life_56\n",
      "470 .  diyaa744\n",
      "471 .  ambrosia_resort\n",
      "472 .  sasha__aery\n",
      "473 .  tubesyummy\n",
      "474 .  arewethereyet10\n",
      "475 .  brijesh898989\n",
      "476 .  shivikhatter98765\n",
      "477 .  _majesticsportsstore\n",
      "478 .  rohannaswa\n",
      "479 .  de.keto\n",
      "480 .  paradise_taste_\n",
      "481 .  rachit.a.k.a.ricknine\n",
      "482 .  travel_street_club\n",
      "483 .  ms.riya_jha__\n",
      "484 .  sipandcapture\n",
      "485 .  stvebck0\n",
      "486 .  devilzone_21\n",
      "487 .  ballerluxuries\n",
      "488 .  kuntal_boydreaming\n",
      "489 .  hazelpowellevans\n",
      "490 .  rahul.dhameja\n",
      "491 .  amitchandras\n",
      "492 .  travelsecretsmagazine\n",
      "493 .  mitu_makadiya013\n",
      "494 .  adi_the_machine__\n",
      "495 .  denbelzerin_155\n",
      "496 .  bakinghappilyft\n",
      "497 .  friends_momos\n",
      "498 .  ozaaditya92\n",
      "499 .  kakicafe\n",
      "500 .  _mrunall\n"
     ]
    }
   ],
   "source": [
    "## 6\n",
    "\n",
    "names = [\"sodelhi\", \"foodtalkindia\"]\n",
    "\n",
    "##extracting the followers\n",
    "no_of_followers = 500                                             ## can be change\n",
    "lst = extract_followers_of_profiles(driver, names, no_of_followers)         \n",
    "sodelhi_followers, foodtalkindia_followers = lst[0], lst[1]\n",
    "\n",
    "## printing the followers\n",
    "print(\"sodelhi followers:\")\n",
    "cnt = 1\n",
    "for i in sodelhi_followers:\n",
    "    print(cnt, \". \", i)\n",
    "    cnt += 1\n",
    "    \n",
    "print()\n",
    "\n",
    "print(\"foodtalkindia followers:\")\n",
    "cnt = 1\n",
    "for i in foodtalkindia_followers:\n",
    "    print(cnt, \". \", i)\n",
    "    cnt += 1\n",
    "    \n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of followers extracted of foodtalkindia : 1008\n",
      "number of followers extracted of prachi_bhardwaj29 : 155\n",
      "number of followings extracted of prachi_bhardwaj29 : 84\n",
      "followers whom i follow but dont follow me , follow the profile_name i.e : foodtalkindia\n"
     ]
    }
   ],
   "source": [
    "## me and profile followers\n",
    "profiles = [username, \"foodtalkindia\"] \n",
    "lst = followers_follow_profile_not_mine(driver, profiles)     ## not including username\n",
    "\n",
    "## printing the followers\n",
    "print(\"followers whom i follow but dont follow me , follow the profile_name i.e :\", profiles[1])\n",
    "cnt = 1\n",
    "for i in lst:\n",
    "    print(cnt, \".\", i)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Story "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def story(driver, profile):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)              ## Explicit Wait\n",
    "    \n",
    "    ## opening profile\n",
    "    search_open(driver, profile)\n",
    "    \n",
    "    pg = driver.page_source\n",
    "    data = bs4.BeautifulSoup(pg,\"lxml\")\n",
    "    \n",
    "    try:\n",
    "        ele = data.find('canvas')\n",
    "        height = int(ele['height'])\n",
    "        width = int(ele['width'])\n",
    "\n",
    "        ## condition for seen story\n",
    "        if height == 131:\n",
    "            print(\"User Has seen the story\")\n",
    "        else:\n",
    "            ## opening the story element\n",
    "            path = '//div[@class = \"XjzKX\"]/div'\n",
    "            btn = wait.until(EC.element_to_be_clickable((By.XPATH,path)))\n",
    "            btn.click()\n",
    "            print(\"Story is Seen\")\n",
    "            \n",
    "            time.sleep(20)\n",
    "        \n",
    "    except Exception:\n",
    "        ## no story\n",
    "        print(\"Has No Story\")\n",
    "        \n",
    "    ## return to home page\n",
    "    home = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[@class = \"oJZym\"]/a')))\n",
    "    home.click()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story is Seen\n"
     ]
    }
   ],
   "source": [
    "## 7\n",
    "\n",
    "profile = 'coding.ninjas'\n",
    "story(driver, profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Closing the Driver\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
